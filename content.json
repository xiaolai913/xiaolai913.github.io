{"meta":{"title":"Salmon","subtitle":null,"description":null,"author":"Vincent Lai","url":"http://salmonlike.com"},"pages":[{"title":"Tags","date":"2016-10-01T14:13:48.000Z","updated":"2016-10-01T14:13:48.000Z","comments":true,"path":"tags/index.html","permalink":"http://salmonlike.com/tags/index.html","excerpt":"","text":""},{"title":"Categories","date":"2016-10-01T14:13:37.000Z","updated":"2016-10-01T14:13:37.000Z","comments":true,"path":"categories/index.html","permalink":"http://salmonlike.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Redis简介&安装部署","date":"2016-12-25T15:14:36.000Z","updated":"2016-12-25T15:14:36.000Z","comments":true,"path":"2016/12/25/Redis简介&安装部署/","link":"","permalink":"http://salmonlike.com/2016/12/25/Redis简介&安装部署/","excerpt":"","text":"#Redis简介&amp;安装部署是什么？ 一种开源的内存型KV/NoSQL存储服务，可用作数据库、缓存或者消息代理（消息的生产和订阅）等1Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster 有啥特点？ 数据主要存储在内存中，响应速度快 KV存储，Value的类型支持string, hash, list, set, sorted set等 支持对KV数据的单点/范围查询，bitmaps, hyperloglogs and geospatial indexes with radius queries （后几种查询目前还没试用过） 支持Pub/Sub(生产者/订阅者)消息消费模式 内建了主从复制、Lua脚本？、LRU内存替换策略、事务？机制 同时支持快照和AOF两种持久化机制 容灾方面不仅支持主从复制，还提供了哨兵（Sentinel)机制以及Redis集群的自动化分片技术来提高系统的可用性 安装部署 当前最新版本：redis 3.2.6 单节点Redis高可用（主从复制+三哨兵）安装教程 启动命令 1234# 服务端启动src/redis-server redis.conf# 客户端连接src/redis-cli -a password 常见问题 make test出错，大多是tcl develop包没安装 java客户端（jedis）访问失败，很可能是没设密码且保护模式开启，修改配置文件配上密码即可 常用命令集合1）连接操作命令quit：关闭连接（connection）auth：简单密码认证help cmd： 查看cmd帮助，例如：help quit 2）持久化save：将数据同步保存到磁盘bgsave：将数据异步保存到磁盘lastsave：返回上次成功将数据保存到磁盘的Unix时戳shundown：将数据同步保存到磁盘，然后关闭服务 3）远程服务控制info：提供服务器的信息和统计monitor：实时转储收到的请求slaveof：改变复制策略设置config：在运行时配置Redis服务器 4）对value操作的命令exists(key)：确认一个key是否存在del(key)：删除一个keytype(key)：返回值的类型keys(pattern)：返回满足给定pattern的所有keyrandomkey：随机返回key空间的一个keyrename(oldname, newname)：重命名keydbsize：返回当前数据库中key的数目expire：设定一个key的活动时间（s）ttl：获得一个key的活动时间select(index)：按索引查询move(key, dbindex)：移动当前数据库中的key到dbindex数据库flushdb：删除当前选择数据库中的所有keyflushall：删除所有数据库中的所有key 5）Stringset(key, value)：给数据库中名称为key的string赋予值valueget(key)：返回数据库中名称为key的string的valuegetset(key, value)：给名称为key的string赋予上一次的valuemget(key1, key2,…, key N)：返回库中多个string的valuesetnx(key, value)：添加string，名称为key，值为valuesetex(key, time, value)：向库中添加string，设定过期时间time (覆盖时过期时间也会被覆盖）mset(key N, value N)：批量设置多个string的值msetnx(key N, value N)：如果所有名称为key i的string都不存在incr(key)：名称为key的string增1操作incrby(key, integer)：名称为key的string增加integerdecr(key)：名称为key的string减1操作decrby(key, integer)：名称为key的string减少integerappend(key, value)：名称为key的string的值附加valuesubstr(key, start, end)：返回名称为key的string的value的子串 6）Listrpush(key, value)：在名称为key的list尾添加一个值为value的元素lpush(key, value)：在名称为key的list头添加一个值为value的 元素llen(key)：返回名称为key的list的长度lrange(key, start, end)：返回名称为key的list中start至end之间的元素ltrim(key, start, end)：截取名称为key的listlindex(key, index)：返回名称为key的list中index位置的元素lset(key, index, value)：给名称为key的list中index位置的元素赋值lrem(key, count, value)：删除count个key的list中值为value的元素lpop(key)：返回并删除名称为key的list中的首元素rpop(key)：返回并删除名称为key的list中的尾元素blpop(key1, key2,… key N, timeout)：lpop命令的block版本。brpop(key1, key2,… key N, timeout)：rpop的block版本。rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 7）Setsadd(key, member)：向名称为key的set中添加元素membersrem(key, member) ：删除名称为key的set中的元素memberspop(key) ：随机返回并删除名称为key的set中一个元素smove(srckey, dstkey, member) ：移到集合元素scard(key) ：返回名称为key的set的基数sismember(key, member) ：member是否是名称为key的set的元素sinter(key1, key2,…key N) ：求交集sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合sunion(key1, (keys)) ：求并集sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合sdiff(key1, (keys)) ：求差集sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合smembers(key) ：返回名称为key的set的所有元素srandmember(key) ：随机返回名称为key的set的一个元素 8）Hashhset(key, field, value)：向名称为key的hash中添加元素fieldhget(key, field)：返回名称为key的hash中field对应的valuehmget(key, (fields))：返回名称为key的hash中field i对应的valuehmset(key, (fields))：向名称为key的hash中添加元素fieldhincrby(key, field, integer)：将名称为key的hash中field的value增加integerhexists(key, field)：名称为key的hash中是否存在键为field的域hdel(key, field)：删除名称为key的hash中键为field的域hlen(key)：返回名称为key的hash中元素个数hkeys(key)：返回名称为key的hash中所有键hvals(key)：返回名称为key的hash中所有键对应的valuehgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value Java客户端访问 使用Jedis操作Redis 待调研内容 Redis Pub/Sub功能实践 Redis集群模式搭建 Redis集群模式分片技术及一致性哈希等 相关链接 Redis官网","categories":[],"tags":[],"keywords":[]},{"title":"Spark简介","slug":"Spark简介","date":"2016-10-01T12:54:41.000Z","updated":"2016-10-01T14:36:47.000Z","comments":true,"path":"2016/10/01/Spark简介/","link":"","permalink":"http://salmonlike.com/2016/10/01/Spark简介/","excerpt":"","text":"Spark是什么？ 一种快速、通用的大规模数据处理引擎 由于spark充分利用的内存计算的特点，也可称作是一种分布式内存计算引擎 Spark的特点 快速：Spark基于内存和并行处理的能力使得它在运行程序时比hadoop MapReduce在内存中计算快100倍，在硬盘数据处理上快10倍??(官方说法，不过大多数场景下的确比Hadoop快不少） 通用：One stack to rule them all! 批处理、交互式查询（SQL）、流式计算、机器学习等Spark样样都能做; 不过大规模离线数据处理、交互式查询是他的强项 易用：提供了丰富的（80+）分布式数据处理算子来简化用户开发分布式程序的代价；支持Scala、Java、Python、R等语言进行程序开发（首推Scala，毕竟Spark底层是用Scala来实现的） 哪都能跑：既可以部署一套单独的Spark集群（即Standalone模式）来跑Spark程序，也可以将Spark程序跑在您现有的Hadoop, Mesos等集群上，甚至还可跑在云上（如Amazon的EC2等） Spark的应用实践 博文 - Spark在腾讯、雅虎、优酷的成功应用 我们团队目前主要用Spark来进行海量数据的离线计算、以及实时日志/消息数据的分析处理 如何快速上手Spark 引言：Spark官网上的各种文档都写得很好通俗易懂，是最好的学习材料；学习Spark贵在实践，好在Spark易用性强且提供了spark shell这个交互式工具来方便用户快速实践各种示例程序 学习步骤推荐： 浏览下官网，过一遍官方文档的Quick Start和Spark Programming Guide两小节（附录中的中文文档翻译的不错也是一种选择） 在学习上面文档的过程中，大部分例子代码都可直接在Spark shell命令行下直接操作，有了实践理解起来也会更有感觉（spark环境的搭建可以参看后面的介绍） 如果光看文档觉得不过瘾的话，有时间可以看看小象科技上Spark的学习视频，讲得挺不错的（可以用我朋友的账户免费看哦） 如果想用Scala来开发Spark程序，那么在真正编写Spark程序前可以简单过一遍Scala的语法（入门期不必太精通，基本语法会了就够用了） 接下来就是实践、实践再实践了。可以在Spark官网上下载最新的Spark源码，源码中有个example目录上面放了很多基本的Spark程序示例，可以比着葫芦画瓢试着写几个Spark小程序 搭建Spark开发环境，运行自己的Spark程序 Spark的运行环境多样，除了standalone集群模式、Yarn/Mesos等第三方托管运行模式、云上运行模式外，也提供了本地运行模式（伪分布式模式）；初学者可以在自己的机器上安装Spark环境直接运行应用程序 进价学习 Spark的原理学习：基础论文学习，核心概念RDD的理解，Spark工作机制探究 Spark源码分析：官网下载Spark源码，学习各个模块的实现细节 Spark本地运行环境安装 先决条件： Linux/类Linux环境（windows的话可以安装个Linux虚拟机，不过还是推荐Linux） JDK 1.7以上，Scala 2.10.x 安装步骤 官网上下载预编译版spark，如这一版 下载解压软件包后，即可通过执行bin目录下的spark-shell即可进入spark交互式编程shell环境 在交互式编程环境下可以一行一行执行Spark程序（交互式环境仅支持用Scala语言），可以试试文档中的各种列子代码哦 学习资料 官网、官方文档 中文文档 小象科技-Spark课程视频 综述论文、RDD原理论文 Scala学习: Scala开发教程、Scala课堂 BDAS Stack: the Berkeley Data Analytics Stack Spark开发环境搭建-Eclipse 其他类似引擎/技术 Flink：类Spark的通用计算引擎，强在流式计算；中文文档 Storm：流式计算引擎","categories":[{"name":"大数据计算","slug":"大数据计算","permalink":"http://salmonlike.com/categories/大数据计算/"}],"tags":[{"name":"spark","slug":"spark","permalink":"http://salmonlike.com/tags/spark/"}],"keywords":[{"name":"大数据计算","slug":"大数据计算","permalink":"http://salmonlike.com/categories/大数据计算/"}]}]}