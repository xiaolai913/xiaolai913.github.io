<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>三文鱼 | 爱虾米</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://salmonlike.com/"/>
  <updated>2016-12-25T15:31:11.000Z</updated>
  <id>http://salmonlike.com/</id>
  
  <author>
    <name>Vincent Lai</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis简介 &amp; 安装部署</title>
    <link href="http://salmonlike.com/2016/12/25/Redis%E7%AE%80%E4%BB%8B&amp;%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://salmonlike.com/2016/12/25/Redis简介&amp;安装部署/</id>
    <published>2016-12-25T15:18:00.000Z</published>
    <updated>2016-12-25T15:31:11.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h3><ul>
<li>一种开源的内存型KV/NoSQL存储服务，可用作数据库、缓存或者消息代理（消息的生产和订阅）等<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="有啥特点？"><a href="#有啥特点？" class="headerlink" title="有啥特点？"></a>有啥特点？</h3><ul>
<li>数据主要存储在内存中，响应速度快</li>
<li>KV存储，Value的类型支持<code>string, hash, list, set, sorted set</code>等</li>
<li>支持对KV数据的单点/范围查询，bitmaps, hyperloglogs and geospatial indexes with radius queries （后几种查询目前还没试用过）</li>
<li>支持<code>Pub/Sub(生产者/订阅者)</code>消息消费模式</li>
<li>内建了主从复制、Lua脚本？、LRU内存替换策略、事务？机制</li>
<li>同时支持<code>快照和AOF</code>两种持久化机制</li>
<li>容灾方面不仅支持<code>主从复制</code>，还提供了<code>哨兵（Sentinel)机制以及Redis集群的自动化分片</code>技术来提高系统的可用性</li>
</ul>
<h3 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h3><ul>
<li>当前最新版本：<a href="http://download.redis.io/releases/redis-3.2.6.tar.gz" target="_blank" rel="external">redis 3.2.6</a></li>
<li><a href="http://www.cnblogs.com/linuxbug/p/5131504.html" target="_blank" rel="external">单节点Redis高可用（主从复制+三哨兵）安装教程</a></li>
<li><p>启动命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># 服务端启动</div><div class="line">src/redis-server redis.conf</div><div class="line"># 客户端连接</div><div class="line">src/redis-cli -a password</div></pre></td></tr></table></figure>
</li>
<li><p>常见问题</p>
<ul>
<li>make test出错，大多是tcl develop包没安装</li>
<li>java客户端（jedis）访问失败，很可能是没设密码且保护模式开启，修改配置文件配上密码即可</li>
</ul>
</li>
</ul>
<h3 id="常用命令集合"><a href="#常用命令集合" class="headerlink" title="常用命令集合"></a>常用命令集合</h3><p>1）连接操作命令<br>quit：关闭连接（connection）<br>auth：简单密码认证<br>help cmd： 查看cmd帮助，例如：help quit</p>
<p>2）持久化<br>save：将数据同步保存到磁盘<br>bgsave：将数据异步保存到磁盘<br>lastsave：返回上次成功将数据保存到磁盘的Unix时戳<br>shundown：将数据同步保存到磁盘，然后关闭服务</p>
<p>3）远程服务控制<br>info：提供服务器的信息和统计<br>monitor：实时转储收到的请求<br>slaveof：改变复制策略设置<br>config：在运行时配置Redis服务器</p>
<p>4）对value操作的命令<br>exists(key)：确认一个key是否存在<br>del(key)：删除一个key<br>type(key)：返回值的类型<br>keys(pattern)：返回满足给定pattern的所有key<br>randomkey：随机返回key空间的一个<br>keyrename(oldname, newname)：重命名key<br>dbsize：返回当前数据库中key的数目<br>expire：设定一个key的活动时间（s）<br>ttl：获得一个key的活动时间<br>select(index)：按索引查询<br>move(key, dbindex)：移动当前数据库中的key到dbindex数据库<br>flushdb：删除当前选择数据库中的所有key<br>flushall：删除所有数据库中的所有key</p>
<p>5）String<br>set(key, value)：给数据库中名称为key的string赋予值value<br>get(key)：返回数据库中名称为key的string的value<br>getset(key, value)：给名称为key的string赋予上一次的value<br>mget(key1, key2,…, key N)：返回库中多个string的value<br>setnx(key, value)：添加string，名称为key，值为value<br>setex(key, time, value)：向库中添加string，设定过期时间time  (覆盖时过期时间也会被覆盖）<br>mset(key N, value N)：批量设置多个string的值<br>msetnx(key N, value N)：如果所有名称为key i的string都不存在<br>incr(key)：名称为key的string增1操作<br>incrby(key, integer)：名称为key的string增加integer<br>decr(key)：名称为key的string减1操作<br>decrby(key, integer)：名称为key的string减少integer<br>append(key, value)：名称为key的string的值附加value<br>substr(key, start, end)：返回名称为key的string的value的子串</p>
<p>6）List<br>rpush(key, value)：在名称为key的list尾添加一个值为value的元素<br>lpush(key, value)：在名称为key的list头添加一个值为value的 元素<br>llen(key)：返回名称为key的list的长度<br>lrange(key, start, end)：返回名称为key的list中start至end之间的元素<br>ltrim(key, start, end)：截取名称为key的list<br>lindex(key, index)：返回名称为key的list中index位置的元素<br>lset(key, index, value)：给名称为key的list中index位置的元素赋值<br>lrem(key, count, value)：删除count个key的list中值为value的元素<br>lpop(key)：返回并删除名称为key的list中的首元素<br>rpop(key)：返回并删除名称为key的list中的尾元素<br>blpop(key1, key2,… key N, timeout)：lpop命令的block版本。<br>brpop(key1, key2,… key N, timeout)：rpop的block版本。<br>rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部</p>
<p>7）Set<br>sadd(key, member)：向名称为key的set中添加元素member<br>srem(key, member) ：删除名称为key的set中的元素member<br>spop(key) ：随机返回并删除名称为key的set中一个元素<br>smove(srckey, dstkey, member) ：移到集合元素<br>scard(key) ：返回名称为key的set的基数<br>sismember(key, member) ：member是否是名称为key的set的元素<br>sinter(key1, key2,…key N) ：求交集<br>sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合<br>sunion(key1, (keys)) ：求并集<br>sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合<br>sdiff(key1, (keys)) ：求差集<br>sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合<br>smembers(key) ：返回名称为key的set的所有元素<br>srandmember(key) ：随机返回名称为key的set的一个元素</p>
<p>8）Hash<br>hset(key, field, value)：向名称为key的hash中添加元素field<br>hget(key, field)：返回名称为key的hash中field对应的value<br>hmget(key, (fields))：返回名称为key的hash中field i对应的value<br>hmset(key, (fields))：向名称为key的hash中添加元素field<br>hincrby(key, field, integer)：将名称为key的hash中field的value增加integer<br>hexists(key, field)：名称为key的hash中是否存在键为field的域<br>hdel(key, field)：删除名称为key的hash中键为field的域<br>hlen(key)：返回名称为key的hash中元素个数<br>hkeys(key)：返回名称为key的hash中所有键<br>hvals(key)：返回名称为key的hash中所有键对应的value<br>hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value</p>
<h3 id="Java客户端访问"><a href="#Java客户端访问" class="headerlink" title="Java客户端访问"></a>Java客户端访问</h3><ul>
<li><a href="http://www.cnblogs.com/liuling/p/2014-4-19-04.html" target="_blank" rel="external">使用Jedis操作Redis</a></li>
</ul>
<h3 id="待调研内容"><a href="#待调研内容" class="headerlink" title="待调研内容"></a>待调研内容</h3><ul>
<li>Redis Pub/Sub功能实践</li>
<li>Redis集群模式搭建</li>
<li>Redis集群模式分片技术及一致性哈希等</li>
</ul>
<h3 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h3><ul>
<li><a href="https://redis.io/" target="_blank" rel="external">Redis官网</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;是什么？&quot;&gt;&lt;a href=&quot;#是什么？&quot; class=&quot;headerlink&quot; title=&quot;是什么？&quot;&gt;&lt;/a&gt;是什么？&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;一种开源的内存型KV/NoSQL存储服务，可用作数据库、缓存或者消息代理（消息的生产和订阅）等&lt;figure c
    
    </summary>
    
      <category term="数据存储" scheme="http://salmonlike.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="redis cache" scheme="http://salmonlike.com/tags/redis-cache/"/>
    
  </entry>
  
  <entry>
    <title>Spark简介</title>
    <link href="http://salmonlike.com/2016/10/01/Spark%E7%AE%80%E4%BB%8B/"/>
    <id>http://salmonlike.com/2016/10/01/Spark简介/</id>
    <published>2016-10-01T12:54:41.000Z</published>
    <updated>2016-10-01T14:36:47.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Spark是什么？"><a href="#Spark是什么？" class="headerlink" title="Spark是什么？"></a>Spark是什么？</h3><ul>
<li>一种快速、通用的大规模数据处理引擎</li>
<li>由于spark充分利用的内存计算的特点，也可称作是一种分布式内存计算引擎</li>
</ul>
<h3 id="Spark的特点"><a href="#Spark的特点" class="headerlink" title="Spark的特点"></a>Spark的特点</h3><ul>
<li>快速：Spark基于内存和并行处理的能力使得它在运行程序时比hadoop MapReduce在内存中计算快100倍，在硬盘数据处理上快10倍??(官方说法，不过大多数场景下的确比Hadoop快不少）</li>
<li>通用：<strong>One stack to rule them all! </strong> 批处理、交互式查询（SQL）、流式计算、机器学习等Spark样样都能做; 不过大规模离线数据处理、交互式查询是他的强项</li>
<li>易用：提供了丰富的（80+）分布式数据处理<a href="https://spark.apache.org/docs/latest/programming-guide.html#transformations" target="_blank" rel="external">算子</a>来简化用户开发分布式程序的代价；支持Scala、Java、Python、R等语言进行程序开发（首推Scala，毕竟Spark底层是用Scala来实现的）</li>
<li>哪都能跑：既可以部署一套单独的Spark集群（即Standalone模式）来跑Spark程序，也可以将Spark程序跑在您现有的Hadoop, Mesos等集群上，甚至还可跑在云上（如Amazon的EC2等）</li>
</ul>
<h3 id="Spark的应用实践"><a href="#Spark的应用实践" class="headerlink" title="Spark的应用实践"></a>Spark的应用实践</h3><ul>
<li><a href="http://database.51cto.com/art/201406/442055.htm" target="_blank" rel="external">博文 - Spark在腾讯、雅虎、优酷的成功应用</a></li>
<li>我们团队目前主要用Spark来进行海量数据的离线计算、以及实时日志/消息数据的分析处理 </li>
</ul>
<h3 id="如何快速上手Spark"><a href="#如何快速上手Spark" class="headerlink" title="如何快速上手Spark"></a>如何快速上手Spark</h3><ul>
<li>引言：Spark官网上的各种文档都写得很好通俗易懂，是最好的学习材料；学习Spark贵在实践，好在Spark易用性强且提供了spark shell这个交互式工具来方便用户快速实践各种示例程序</li>
<li>学习步骤推荐：<ul>
<li>浏览下官网，过一遍官方文档的Quick Start和Spark Programming Guide两小节（附录中的中文文档翻译的不错也是一种选择）</li>
<li>在学习上面文档的过程中，大部分例子代码都可直接在Spark shell命令行下直接操作，有了实践理解起来也会更有感觉（spark环境的搭建可以参看后面的介绍）</li>
<li>如果光看文档觉得不过瘾的话，有时间可以看看小象科技上Spark的学习视频，讲得挺不错的（可以用我朋友的账户免费看哦）</li>
<li>如果想用Scala来开发Spark程序，那么在真正编写Spark程序前可以简单过一遍Scala的语法（入门期不必太精通，基本语法会了就够用了）</li>
<li>接下来就是实践、实践再实践了。可以在Spark官网上下载最新的<a href="https://spark.apache.org/downloads.html" target="_blank" rel="external">Spark源码</a>，源码中有个example目录上面放了很多基本的Spark程序示例，可以比着葫芦画瓢试着写几个Spark小程序</li>
<li>搭建Spark开发环境，运行自己的Spark程序</li>
<li>Spark的运行环境多样，除了standalone集群模式、Yarn/Mesos等第三方托管运行模式、云上运行模式外，也提供了本地运行模式（伪分布式模式）；初学者可以在自己的机器上安装Spark环境直接运行应用程序</li>
</ul>
</li>
<li>进价学习<ul>
<li>Spark的原理学习：基础论文学习，核心概念RDD的理解，Spark工作机制探究</li>
<li>Spark源码分析：官网下载Spark源码，学习各个模块的实现细节</li>
</ul>
</li>
</ul>
<h3 id="Spark本地运行环境安装"><a href="#Spark本地运行环境安装" class="headerlink" title="Spark本地运行环境安装"></a>Spark本地运行环境安装</h3><ul>
<li>先决条件：<ul>
<li>Linux/类Linux环境（windows的话可以安装个Linux虚拟机，不过还是推荐Linux）</li>
<li>JDK 1.7以上，<a href="http://www.scala-lang.org/" target="_blank" rel="external">Scala 2.10.x</a></li>
</ul>
</li>
<li>安装步骤<ul>
<li><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">官网</a>上下载预编译版spark，如<a href="http://mirrors.cnnic.cn/apache/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz" target="_blank" rel="external">这一版</a></li>
<li>下载解压软件包后，即可通过执行bin目录下的spark-shell即可进入spark交互式编程shell环境</li>
<li>在交互式编程环境下可以一行一行执行Spark程序（交互式环境仅支持用Scala语言），可以试试文档中的各种列子代码哦</li>
</ul>
</li>
</ul>
<h3 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h3><ul>
<li><a href="https://spark.apache.org/" target="_blank" rel="external">官网</a>、<a href="https://spark.apache.org/docs/latest/" target="_blank" rel="external">官方文档</a></li>
<li><a href="https://endymecy.gitbooks.io/spark-programming-guide-zh-cn/content/" target="_blank" rel="external">中文文档</a></li>
<li><a href="http://www.chinahadoop.cn/course/114" target="_blank" rel="external">小象科技-Spark课程视频</a></li>
<li><a href="http://www.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-12.pdf" target="_blank" rel="external">综述论文</a>、<a href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf" target="_blank" rel="external">RDD原理论文</a></li>
<li>Scala学习: <a href="http://wiki.jikexueyuan.com/project/scala-development-guide/" target="_blank" rel="external">Scala开发教程</a>、<a href="http://twitter.github.io/scala_school/zh_cn/" target="_blank" rel="external">Scala课堂</a></li>
<li><a href="https://amplab.cs.berkeley.edu/software/" target="_blank" rel="external">BDAS Stack</a>: the Berkeley Data Analytics Stack</li>
<li><a href="http://www.cnblogs.com/simplestupid/p/4687507.html" target="_blank" rel="external">Spark开发环境搭建-Eclipse</a></li>
</ul>
<h3 id="其他类似引擎-技术"><a href="#其他类似引擎-技术" class="headerlink" title="其他类似引擎/技术"></a>其他类似引擎/技术</h3><ul>
<li><a href="https://flink.apache.org/" target="_blank" rel="external">Flink</a>：类Spark的通用计算引擎，强在流式计算；<a href="http://doc.flink-china.org/" target="_blank" rel="external">中文文档</a></li>
<li><a href="http://storm.apache.org/" target="_blank" rel="external">Storm</a>：流式计算引擎</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Spark是什么？&quot;&gt;&lt;a href=&quot;#Spark是什么？&quot; class=&quot;headerlink&quot; title=&quot;Spark是什么？&quot;&gt;&lt;/a&gt;Spark是什么？&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;一种快速、通用的大规模数据处理引擎&lt;/li&gt;
&lt;li&gt;由于spark充分
    
    </summary>
    
      <category term="大数据计算" scheme="http://salmonlike.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="spark" scheme="http://salmonlike.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Kafka简介</title>
    <link href="http://salmonlike.com/2015/12/15/Kafka%E7%AE%80%E4%BB%8B/"/>
    <id>http://salmonlike.com/2015/12/15/Kafka简介/</id>
    <published>2015-12-15T12:54:41.000Z</published>
    <updated>2017-05-04T22:48:15.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Kafka基础"><a href="#Kafka基础" class="headerlink" title="Kafka基础"></a>Kafka基础</h2><hr>
<h3 id="是什么？"><a href="#是什么？" class="headerlink" title="是什么？"></a>是什么？</h3><ul>
<li>分布式消息系统（发布-订阅）</li>
<li>实时流式系统</li>
</ul>
<h3 id="有啥特点？"><a href="#有啥特点？" class="headerlink" title="有啥特点？"></a>有啥特点？</h3><ul>
<li>分布式，可扩展</li>
<li>高吞吐、低延迟（超一流的读写性能！)</li>
<li>容错，高可靠（支持ack)</li>
<li>支持多订阅，负载均衡</li>
<li>消息持久化，除了可用于实时消费也可用于离线分析，ETL等操作</li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul>
<li>数据缓冲、    异步通信、日志汇集、系统解耦等</li>
</ul>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="http://kafka.apache.org/images/producer_consumer.png" alt="kafka架构图"></p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ol>
<li>message：key/value对。其中value即消息，key用来进行partition的哈希（除非用户自己明确指定分区）</li>
<li>Topic：用于划分Message的逻辑概念，一个Topic可以分布在多个Broker上。</li>
<li><strong>Partition</strong>：是Kafka中横向扩展和一切并行化的基础，每个Topic都至少被切分为1个Partition。</li>
<li>Offset：消息在Partition中的编号，编号顺序不跨Partition。</li>
<li><strong>Consumer</strong>：用于从Broker中取出/消费Message。</li>
<li><strong>Producer</strong>：用于往Broker中发送/生产Message。</li>
<li>Replication：Kafka支持以Partition为单位对Message进行冗余备份，每个Partition都可以配置至少1个Replication(当仅1个Replication时即仅该Partition本身)。</li>
<li>Leader：每个Replication集合中的Partition都会选出一个唯一的Leader，所有的读写请求都由Leader处理。其他Replicas从Leader处把数据更新同步到本地，过程类似大家熟悉的MySQL中的Binlog同步。</li>
<li><strong>Broker</strong>：Kafka中使用Broker来接受Producer和Consumer的请求，并把Message持久化到本地磁盘。每个Cluster当中会选举出一个Broker来担任Controller，负责处理Partition的Leader选举，协调Partition迁移等工作。</li>
<li>ISR(In-Sync Replica)：是Replicas的一个子集，表示目前Alive且与Leader能够“Catch-up”的Replicas集合。由于读写都是首先落到Leader上，所以一般来说通过同步机制从Leader上拉取数据的Replica都会和Leader有一些延迟(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该Replica踢出ISR。每个Partition都有它自己独立的ISR。</li>
</ol>
<h3 id="常用命令："><a href="#常用命令：" class="headerlink" title="常用命令："></a>常用命令：</h3><ol>
<li>启动服务</li>
</ol>
<ul>
<li>启动zk: bin/zookeeper-server-start.sh config/zookeeper.properties</li>
<li>启动kafka broker: bin/kafka-server-start.sh config/server.properties</li>
<li>创建topic: bin/kafka-topics.sh –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic test</li>
<li>产生消息: bin/kafka-console-producer.sh –broker-list localhost:9092 –topic test</li>
<li>消费消息：bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test –from-beginning</li>
</ul>
<h3 id="kafka监控工具"><a href="#kafka监控工具" class="headerlink" title="kafka监控工具"></a>kafka监控工具</h3><ul>
<li>Kafka Web Conslole</li>
<li><a href="https://github.com/yahoo/kafka-manager" target="_blank" rel="external">Kafka Manager</a></li>
<li><a href="https://github.com/quantifind/KafkaOffsetMonitor" target="_blank" rel="external">KafkaOffsetMonitor</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Kafka基础&quot;&gt;&lt;a href=&quot;#Kafka基础&quot; class=&quot;headerlink&quot; title=&quot;Kafka基础&quot;&gt;&lt;/a&gt;Kafka基础&lt;/h2&gt;&lt;hr&gt;
&lt;h3 id=&quot;是什么？&quot;&gt;&lt;a href=&quot;#是什么？&quot; class=&quot;headerlink&quot;
    
    </summary>
    
      <category term="流式处理" scheme="http://salmonlike.com/categories/%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86/"/>
    
    
      <category term="kafka" scheme="http://salmonlike.com/tags/kafka/"/>
    
  </entry>
  
</feed>
